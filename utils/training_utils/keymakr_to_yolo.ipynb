{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Required Libraries and Tools\n",
    "Import necessary libraries and set up FFmpeg path. Include error handling for missing dependencies and file paths validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input keymakr dirs containing the videos, .images dir and .json file\n",
    "file_dirs = ['Indonesia', 'Malaysia', 'Phillipines', 'Singapore']\n",
    "\n",
    "data_split = [80, 20, 0] # Train, Val, Test\n",
    "\n",
    "# Set frame extraction rate\n",
    "fps_extraction = 10  # Extract 1 frame every 10 frames\n",
    "\n",
    "# Set up FFmpeg path\n",
    "ffmpeg_path = r'C:\\ffmpeg\\bin\\ffmpeg.exe'\n",
    "\n",
    "if sum(data_split) != 100:\n",
    "    raise ValueError(f\"data_split must sum to 100. Current sum is {sum(data_split)}. Please rewrite the data_split variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ultralytics --quiet\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from ultralytics.data.utils import compress_one_image\n",
    "from ultralytics.utils.downloads import zip_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(ffmpeg_path):\n",
    "    raise FileNotFoundError(f\"FFmpeg not found at {ffmpeg_path}. Please check the path and try again.\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Annotations\n",
    "Load JSON annotation files, extract class information, and create class mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "temp_dataset = 'temp'\n",
    "\n",
    "# Process each directory to extract class information\n",
    "for dir in file_dirs:\n",
    "    files = os.listdir(dir)\n",
    "    json_file = next((f for f in files if f.endswith('.json')), None)\n",
    "    if json_file:\n",
    "        json_file = os.path.join(dir, json_file)\n",
    "\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    data = list(data)\n",
    "    zero_frame = data[0]\n",
    "\n",
    "    for obj in zero_frame.get('objects', []):\n",
    "        cls = obj.get('attributes', {'Vehicle_type' : 'Pedestrian'}).get('Vehicle_type')\n",
    "        if cls not in classes :\n",
    "            classes.append(cls)\n",
    "\n",
    "classes.sort()\n",
    "\n",
    "reverse_classes = {cls : i for i, cls in enumerate(classes)}\n",
    "classes = {i : cls for i, cls in enumerate(classes)}\n",
    "\n",
    "print(f'{classes=}')\n",
    "print(f'{reverse_classes=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Annotations to YOLO Format & Extract Video Frames\n",
    "Convert bounding box coordinates to YOLO format (normalized coordinates). Write labels to text files.\n",
    "Use FFmpeg to extract frames from videos at specified intervals according to the extraction rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_empty_frames(frames):\n",
    "    ''' Expects the data with the zeroframe (metadata item at beginning of keymakr json removed) '''\n",
    "    # Find frames with no objects\n",
    "    empty_frames = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        if len(frame.get('objects', [])) == 0:\n",
    "            empty_frames.append(i)\n",
    "\n",
    "    return empty_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in file_dirs:\n",
    "    files = os.listdir(dir)\n",
    "    json_file = next((f for f in files if f.endswith('.json')), None)\n",
    "    if json_file:\n",
    "        json_file = os.path.join(dir, json_file)\n",
    "\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    zero_frame = data.pop(0)\n",
    "\n",
    "    empty_frames = find_empty_frames([zero_frame] + data)\n",
    "    if empty_frames:\n",
    "        print(f\"Skipping {len(empty_frames)} empty frames in {dir}\")\n",
    "        \n",
    "    img_width = zero_frame.get('width', 0)\n",
    "    img_height = zero_frame.get('height', 0)\n",
    "\n",
    "    objects = {}\n",
    "    for obj in zero_frame.get('objects', []):\n",
    "        nm = obj.get('nm')\n",
    "        cls = obj.get('attributes', {'Vehicle_type' : 'Pedestrian'}).get('Vehicle_type')\n",
    "        objects[nm] = cls\n",
    "\n",
    "    labels_dir = os.path.join(temp_dataset,os.path.basename(dir), 'labels')\n",
    "    os.makedirs(labels_dir, exist_ok=False)\n",
    "\n",
    "    for i, frame in enumerate(data):\n",
    "        if i in empty_frames:\n",
    "                continue\n",
    "        frame_file = os.path.join(labels_dir, f'{i+1}.txt')\n",
    "        with open(frame_file, 'w') as f:\n",
    "            for obj in frame.get('objects', []):\n",
    "                nm = obj.get('nm')\n",
    "                cls = objects.get(nm, 'Unknown')\n",
    "                cls_id = reverse_classes.get(cls, reverse_classes['Pedestrian'])\n",
    "                x1 = obj.get('x1', 0)\n",
    "                y1 = obj.get('y1', 0)\n",
    "                x2 = obj.get('x2', 0)\n",
    "                y2 = obj.get('y2', 0)\n",
    "                width, height = x2 - x1, y2 - y1\n",
    "                x_center, y_center = (x2 + x1) / 2, (y2 + y1) / 2\n",
    "                norm_width, norm_x_center = width / img_width, x_center / img_width\n",
    "                norm_height, norm_y_center = height / img_height, y_center / img_height\n",
    "                f.write(f'{cls_id} {norm_x_center} {norm_y_center} {norm_width} {norm_height}\\n')\n",
    "\n",
    "    total_frames = len(data) - len(empty_frames)\n",
    "    print(f'Processed {dir} labels into {labels_dir} : {total_frames} frames labeled, {len(objects)} unique objects found')\n",
    "\n",
    "    video_file = next((f for f in files if f.endswith('.mp4')), None)\n",
    "    if video_file:\n",
    "        video_file = os.path.join(dir, video_file)\n",
    "        images = os.path.join(temp_dataset,os.path.basename(dir), 'images')\n",
    "        os.makedirs(images, exist_ok=False)\n",
    "        \n",
    "        os.system(f'{ffmpeg_path} -i \"{video_file}\" -vf \"select=not(mod(n\\,{fps_extraction}))\" -vsync vfr {images}/%d.jpg -hide_banner -loglevel error')\n",
    "        for empty_frame in empty_frames:\n",
    "            empty_frame_path = os.path.join(images, f'{empty_frame}.jpg')\n",
    "            if os.path.exists(empty_frame_path):\n",
    "                os.remove(empty_frame_path)\n",
    "        print(f'Processed {dir} video into {images} : {len(os.listdir(images))} frames extracted from {video_file}')\n",
    "        if total_frames != len(os.listdir(images)):\n",
    "            logging.error(f'{total_frames} frames labeled but {len(os.listdir(images))} frames extracted from {video_file} ; check fps extraction count (currently set to {fps_extraction})\\n Script will continue but this may cause issues')\n",
    "\n",
    "for f in Path(temp_dataset).rglob(\"*.jpg\"):\n",
    "    compress_one_image(f)\n",
    "print(\"All images compressed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset Structure\n",
    "Create the dataset directory structure with train/val/test splits and corresponding images/labels subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"dataset\"\n",
    "count = 0\n",
    "while os.path.exists(dataset_root):\n",
    "    count += 1\n",
    "    dataset_root = f\"dataset_{count}\"\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "for split in splits:\n",
    "    for subdir in [\"images\", \"labels\"]:\n",
    "        os.makedirs(os.path.join(dataset_root, split, subdir), exist_ok=True)\n",
    "\n",
    "for dir in os.listdir(temp_dataset):\n",
    "    src_images = os.path.join(temp_dataset, dir, \"images\")\n",
    "    src_labels = os.path.join(temp_dataset, dir, \"labels\")\n",
    "    \n",
    "    image_files = sorted([f for f in os.listdir(src_images) if f.endswith('.jpg')])\n",
    "    total_files = len(image_files)\n",
    "    \n",
    "    train_size = int(total_files * data_split[0] / 100)\n",
    "    val_size = int(total_files * data_split[1] / 100)\n",
    "    # test_size will be the remainder\n",
    "    \n",
    "    random.seed('Alto Zafferano')\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    train_files = image_files[:train_size]\n",
    "    val_files = image_files[train_size:train_size + val_size]\n",
    "    test_files = image_files[train_size + val_size:]\n",
    "    \n",
    "    for files, split in zip([train_files, val_files, test_files], splits):\n",
    "        for img_file in files:\n",
    "            # Get corresponding label txt\n",
    "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "            \n",
    "            shutil.copy2(\n",
    "                os.path.join(src_images, img_file),\n",
    "                os.path.join(dataset_root, split, \"images\", f\"{dir}_{img_file}\")\n",
    "            )\n",
    "            \n",
    "            # Copy label\n",
    "            shutil.copy2(\n",
    "                os.path.join(src_labels, label_file),\n",
    "                os.path.join(dataset_root, split, \"labels\", f\"{dir}_{label_file}\")\n",
    "            )\n",
    "    print(f\"Processed {dir} into train({train_size})/val({val_size})/test({total_files-train_size-val_size}) split\")\n",
    "\n",
    "shutil.rmtree(temp_dataset)\n",
    "print(\"Temporary dataset removed\")\n",
    "\n",
    "print(f\"Dataset created in {dataset_root} directory :\") \n",
    "print(f\"    {len(os.listdir(os.path.join(dataset_root, splits[0], \"images\")))} train images\")\n",
    "print(f\"    {len(os.listdir(os.path.join(dataset_root, splits[1], \"images\")))} val images\")\n",
    "print(f\"    {len(os.listdir(os.path.join(dataset_root, splits[2], \"images\")))} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write data.yaml file\n",
    "Write the data.yaml file with class names and paths to train/val/test image directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = {\n",
    "    'train': '../train/images',\n",
    "    'val': '../val/images', \n",
    "    'test': '../test/images',\n",
    "    'nc': len(classes),\n",
    "    'names': classes\n",
    "    }\n",
    "\n",
    "with open(f'{dataset_root}/data.yaml', 'w') as f:\n",
    "    yaml.dump(yaml_content, f, sort_keys=False)\n",
    "print(f\"Created dataset configuration file: {dataset_root}/data.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress and export dataset\n",
    "Export it as a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_directory(dataset_root)\n",
    "print(f\"Dataset compressed in {dataset_root}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
